{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:27.384643379Z",
     "start_time": "2023-08-20T20:23:26.219755605Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "from librosa.filters import mel as librosa_mel_fn\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "#print mel spectrogram using librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Define the URL for the LJSpeech dataset\n",
    "LJSPEECH_URL = \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\"\n",
    "LJSPEECH_PATH = \"LJSpeech-1.1.tar.bz2\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:27.943457923Z",
     "start_time": "2023-08-20T20:23:27.941373678Z"
    }
   },
   "id": "dff33a6ca97e3b8d"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Download the LJSpeech dataset\n",
    "response = requests.get(LJSPEECH_URL, stream=True)\n",
    "file_size = int(response.headers['Content-Length'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:31.134257563Z",
     "start_time": "2023-08-20T20:23:28.281026813Z"
    }
   },
   "id": "71d3e2feb1709085"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# with open(LJSPEECH_PATH, 'wb') as file:\n",
    "#     for data in tqdm(response.iter_content(), total=file_size, unit=\"B\", unit_scale=True, desc=\"Downloading LJSpeech\"):\n",
    "#         file.write(data)\n",
    "# \n",
    "# # Unzip the downloaded dataset\n",
    "# if LJSPEECH_PATH.endswith(\".tar.bz2\"):\n",
    "#     import tarfile\n",
    "#     with tarfile.open(LJSPEECH_PATH, 'r:bz2') as archive:\n",
    "#         archive.extractall()\n",
    "#         print(\"Extraction Complete!\")\n",
    "# else:\n",
    "#     print(\"Unknown format: Cannot extract!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:31.134369562Z",
     "start_time": "2023-08-20T20:23:31.114562976Z"
    }
   },
   "id": "26c1b81a52da7be3"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"mel\": {\n",
    "        \"frame_length\": 1024,\n",
    "        \"n_fft\": 1024,\n",
    "        \"num_mels\": 80,\n",
    "        \"sample_rate\": 22050,\n",
    "        \"win_length\": 1024,\n",
    "        \"hop_length\": 256,\n",
    "        \"fmin\": 0,\n",
    "        \"fmax\": 8000,\n",
    "    },\n",
    "    \"segment_length\": 8192,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:31.151972777Z",
     "start_time": "2023-08-20T20:23:31.115838052Z"
    }
   },
   "id": "269cc00c3c1278f3"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def mel_spec(y, config):\n",
    "    # Get the mel-spectrogram\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=y,\n",
    "        sr=config[\"mel\"][\"sample_rate\"],\n",
    "        n_fft=config[\"mel\"][\"n_fft\"],\n",
    "        hop_length=config[\"mel\"][\"hop_length\"],\n",
    "        win_length=config[\"mel\"][\"win_length\"],\n",
    "        window=\"hann\",\n",
    "        center=True,\n",
    "        pad_mode=\"edge\",\n",
    "        power=2.0,\n",
    "        n_mels=config[\"mel\"][\"num_mels\"],\n",
    "        fmin=config[\"mel\"][\"fmin\"],\n",
    "        fmax=config[\"mel\"][\"fmax\"],\n",
    "    )\n",
    "    log_mel_spec = librosa.power_to_db(mel_spec, ref=1.0, amin=1e-5, top_db=None)\n",
    "    return log_mel_spec\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:31.181939096Z",
     "start_time": "2023-08-20T20:23:31.181794704Z"
    }
   },
   "id": "c76321dba0965d81"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "mel_basis = {}\n",
    "hann_window = {}\n",
    "\n",
    "def dynamic_range_compression_torch(x, C=1, clip_val=1e-5):\n",
    "    return torch.log(torch.clamp(x, min=clip_val) * C)\n",
    "\n",
    "def spectral_normalize_torch(magnitudes):\n",
    "    output = dynamic_range_compression_torch(magnitudes)\n",
    "    return output\n",
    "\n",
    "def mel_spectrogram(y, center=False):\n",
    "    num_mels = config[\"mel\"][\"num_mels\"]\n",
    "    n_fft = config[\"mel\"][\"n_fft\"]\n",
    "    hop_size = config[\"mel\"][\"hop_length\"]\n",
    "    win_size = config[\"mel\"][\"win_length\"]\n",
    "    fmin = config[\"mel\"][\"fmin\"]\n",
    "    fmax = config[\"mel\"][\"fmax\"]\n",
    "    sampling_rate = config[\"mel\"][\"sample_rate\"]\n",
    "    if torch.min(y) < -1.:\n",
    "        print('min value is ', torch.min(y))\n",
    "    if torch.max(y) > 1.:\n",
    "        print('max value is ', torch.max(y))\n",
    "\n",
    "    global mel_basis, hann_window\n",
    "    if fmax not in mel_basis:\n",
    "        mel = librosa_mel_fn(sr=sampling_rate, n_fft=n_fft, n_mels=num_mels, fmin=fmin, fmax=fmax)\n",
    "        mel_basis[str(fmax)+'_'+str(y.device)] = torch.from_numpy(mel).float().to(y.device)\n",
    "        hann_window[str(y.device)] = torch.hann_window(win_size).to(y.device)\n",
    "\n",
    "    y = torch.nn.functional.pad(y.unsqueeze(1), (int((n_fft-hop_size)/2), int((n_fft-hop_size)/2)), mode='reflect')\n",
    "    y = y.squeeze(1)\n",
    "\n",
    "    spec = torch.stft(y, n_fft, hop_length=hop_size, win_length=win_size, window=hann_window[str(y.device)],\n",
    "                      center=center, pad_mode='reflect', normalized=False, onesided=True,return_complex=False)\n",
    "\n",
    "    spec = torch.sqrt(spec.pow(2).sum(-1)+(1e-9))\n",
    "\n",
    "    spec = torch.matmul(mel_basis[str(fmax)+'_'+str(y.device)], spec)\n",
    "    spec = spectral_normalize_torch(spec)\n",
    "\n",
    "    return spec\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:31.182028225Z",
     "start_time": "2023-08-20T20:23:31.181872598Z"
    }
   },
   "id": "7dc0ba5b09eecae4"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def load_wav(path, config):\n",
    "    # Load the wav file\n",
    "    wav, _ = librosa.load(path, sr=config[\"mel\"][\"sample_rate\"])\n",
    "    return wav"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:31.182062460Z",
     "start_time": "2023-08-20T20:23:31.181904501Z"
    }
   },
   "id": "a30aa388df056cef"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8192])\n",
      "torch.Size([1, 80, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuro/miniconda3/envs/test/lib/python3.10/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# test sample\n",
    "wav = load_wav('LJSpeech-1.1/wavs/LJ001-0001.wav', config)\n",
    "wav = wav[:8192]\n",
    "wav = torch.from_numpy(wav).float()\n",
    "wav = wav.unsqueeze(0)\n",
    "mel = mel_spectrogram(wav)\n",
    "print(wav.shape)\n",
    "print(mel.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:31.557869374Z",
     "start_time": "2023-08-20T20:23:31.181928422Z"
    }
   },
   "id": "15aa52a27da086b"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def plot_mel_spectrogram(mel):\n",
    "    mel = mel.numpy()\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(np.flip(mel, axis=0), cmap='inferno', aspect='auto')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel Spectrogram')\n",
    "    plt.xlabel('Time Frame')\n",
    "    plt.ylabel('Mel Frequency Bin')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:31.557955241Z",
     "start_time": "2023-08-20T20:23:31.552086546Z"
    }
   },
   "id": "b5edb9a6251d9297"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "root_dir = 'LJSpeech-1.1/wavs'\n",
    "class MelDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.files_list = [f for f in os.listdir(root_dir) if f.endswith(\".wav\")]\n",
    "        self.segment_size = config[\"segment_length\"] * 10\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_file = self.files_list[idx]\n",
    "        wav = load_wav(os.path.join(root_dir, audio_file), config)\n",
    "        # implemenmt same above code using numpy\n",
    "        if wav.shape[0] >= self.segment_size:\n",
    "            start = np.random.randint(0, wav.shape[0] - self.segment_size + 1, (1,)).item()\n",
    "            wav = wav[start:start+self.segment_size]\n",
    "        else:\n",
    "            pad_amount = self.segment_size - wav.shape[0]\n",
    "            wav = np.pad(wav, (0, pad_amount), 'constant')\n",
    "        \n",
    "\n",
    "        # wav = wav[:,None,:]\n",
    "        wav = wav[None,:]\n",
    "        wav = torch.from_numpy(wav).float()\n",
    "        # For mel, compute the corresponding segment\n",
    "        mel = mel_spectrogram(wav)\n",
    "        mel = mel.squeeze(0)\n",
    "        return wav, mel\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:31.571339630Z",
     "start_time": "2023-08-20T20:23:31.554340538Z"
    }
   },
   "id": "9027e228eface499"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 =weight_norm(nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding='same', dilation=1)) \n",
    "        self.conv2 =weight_norm(nn.Conv1d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, padding='same', dilation=1)) \n",
    "        \n",
    "        self.conv3 =weight_norm(nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding='same', dilation=3)) \n",
    "        self.conv4 = weight_norm(nn.Conv1d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, padding='same', dilation=1))\n",
    "        \n",
    "        self.conv5 =weight_norm(nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding='same', dilation=5)) \n",
    "        self.conv6 = weight_norm(nn.Conv1d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, padding='same', dilation=1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.leaky_relu(self.conv1(residual))\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        residual = x + residual\n",
    "        x = F.leaky_relu(self.conv3(residual))\n",
    "        x = F.leaky_relu(self.conv4(x))\n",
    "        residual = x + residual\n",
    "        x = F.leaky_relu(self.conv5(residual))\n",
    "        x = F.leaky_relu(self.conv6(x))\n",
    "        residual = x + residual\n",
    "        return residual"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:31.595812957Z",
     "start_time": "2023-08-20T20:23:31.568707964Z"
    }
   },
   "id": "75ce1deb94817cff"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class DescriminatorBlock(nn.Module):\n",
    "    def __init__(self, in_channels=1):\n",
    "        super(DescriminatorBlock,self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=15, stride=1, padding=7))\n",
    "        self.conv2 = weight_norm(nn.Conv1d(in_channels=16, out_channels=64, kernel_size=41, stride=4, padding=20, groups=4))\n",
    "        \n",
    "        self.conv3 = weight_norm(nn.Conv1d(in_channels=64, out_channels=256, kernel_size=41, stride=4, padding=20, groups=16))\n",
    "        self.conv4 = weight_norm(nn.Conv1d(in_channels=256, out_channels=1024, kernel_size=41, stride=4, padding=20, groups=64))\n",
    "        \n",
    "        self.conv5 = weight_norm(nn.Conv1d(in_channels=1024, out_channels=1024, kernel_size=41, stride=4, padding=20, groups=256))\n",
    "        self.conv6 = weight_norm(nn.Conv1d(in_channels=1024, out_channels=1024, kernel_size=5, stride=1, padding=2))\n",
    "        self.conv7 = weight_norm(nn.Conv1d(in_channels=1024, out_channels=1, kernel_size=3, stride=1, padding=1))\n",
    "    def forward(self, x):\n",
    "        layer_1 = F.leaky_relu(self.conv1(x))\n",
    "        # print(\"============ layer 1\",layer_1.shape)\n",
    "        layer_2 = F.leaky_relu(self.conv2(layer_1))\n",
    "        # print(\"============ layer 2\",layer_2.shape)\n",
    "        layer_3 = F.leaky_relu(self.conv3(layer_2))\n",
    "        # print(\"============ layer 3\",layer_3.shape)\n",
    "        layer_4 = F.leaky_relu(self.conv4(layer_3))\n",
    "        # print(\"============ layer 4\",layer_4.shape)\n",
    "        layer_5 = F.leaky_relu(self.conv5(layer_4))\n",
    "        # print(\"============ layer 5\",layer_5.shape)\n",
    "        layer_6 = F.leaky_relu(self.conv6(layer_5))\n",
    "        # print(\"============ layer 6\",layer_6.shape)\n",
    "        result = self.conv7(layer_6)\n",
    "        # print(\"============ result\",result.shape)\n",
    "        return [layer_1, layer_2, layer_3, layer_4, layer_5, layer_6, result]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:31.623127152Z",
     "start_time": "2023-08-20T20:23:31.580151107Z"
    }
   },
   "id": "af85eb4cbc5efb27"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class UpSampler(nn.Module):\n",
    "    def __init__(self, up_sampling_factor, in_channels, out_channels, kernel_size):\n",
    "        super(UpSampler, self).__init__()\n",
    "        self.up_sampling_factor = up_sampling_factor\n",
    "        self.conv_t = weight_norm(nn.ConvTranspose1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=up_sampling_factor, padding=(kernel_size-up_sampling_factor)//2))\n",
    "        self.res_block = ResidualBlock(out_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv_t(x))\n",
    "        x = self.res_block(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:31.623212629Z",
     "start_time": "2023-08-20T20:23:31.621777904Z"
    }
   },
   "id": "a8dec3ace9b677bb"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(in_channels=80, out_channels=512, kernel_size=7, stride=1, padding=3))\n",
    "        self.up_sampler_1 = UpSampler(8, 512, 256, 16)\n",
    "        self.up_sampler_2 = UpSampler(8, 256, 128,16)\n",
    "        self.up_sampler_3 = UpSampler(2, 128, 64,4)\n",
    "        self.up_sampler_4 = UpSampler(2, 64, 32,4)\n",
    "        self.conv_out = weight_norm(nn.Conv1d(in_channels=32, out_channels=1, kernel_size=7, stride=1, padding=3))\n",
    "    def forward(self,x):\n",
    "        # print(\"======= gen 1\", x.shape)\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        # print(\"======= gen 2\", x.shape)\n",
    "        x = self.up_sampler_1(x)\n",
    "        # print(\"======= gen 3\", x.shape)\n",
    "        x = self.up_sampler_2(x)\n",
    "        # print(\"======= gen 4\", x.shape)\n",
    "        x = self.up_sampler_3(x)\n",
    "        # print(\"======= gen 5\", x.shape)\n",
    "        x = self.up_sampler_4(x)\n",
    "        # print(\"======= gen 6\", x.shape)\n",
    "        x = self.conv_out(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:31.665831728Z",
     "start_time": "2023-08-20T20:23:31.621809798Z"
    }
   },
   "id": "553dc797e1e1957b"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class Descriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Descriminator, self).__init__()\n",
    "        self.desc_block_1 = DescriminatorBlock()\n",
    "        self.desc_block_2 = DescriminatorBlock()\n",
    "        self.desc_block_3 = DescriminatorBlock()\n",
    "        self.avg_pool_1 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "        self.avg_pool_2 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(\"==========input\", x.shape)\n",
    "        out_1  = self.desc_block_1(x)\n",
    "        # print(\"==== desc 1\", out_1[-1].shape)\n",
    "        x = self.avg_pool_1(x)\n",
    "        # print(\"==== avg pool 1\", x.shape)\n",
    "        out_2 = self.desc_block_2(x)\n",
    "        # print(\"==== desc 2\", out_2[-1].shape)\n",
    "        x = self.avg_pool_2(x)\n",
    "        out_3 = self.desc_block_3(x)\n",
    "        # print(\"==== desc 3\", out_3[-1].shape)\n",
    "        return [out_1, out_2, out_3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:31.665938745Z",
     "start_time": "2023-08-20T20:23:31.665799944Z"
    }
   },
   "id": "3337a96259be557e"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# prepare data loader and split train and test ratio\n",
    "dataset = MelDataset(root_dir='LJSpeech-1.1/wavs')\n",
    "batch_size = 16\n",
    "train_size = int(0.9 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:32.523791418Z",
     "start_time": "2023-08-20T20:23:32.511087613Z"
    }
   },
   "id": "348360f72e61af6"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************\n",
      "torch.Size([16, 1, 81920])\n"
     ]
    }
   ],
   "source": [
    "# load single sample and break\n",
    "for i, data in enumerate(train_loader):\n",
    "    wav, mel = data\n",
    "    print(\"*********************\")\n",
    "    print(wav.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:33.959190472Z",
     "start_time": "2023-08-20T20:23:33.810965504Z"
    }
   },
   "id": "eeba9a9f1264e927"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def generator_loss(fake_disc_output):\n",
    "    loss = 0\n",
    "    gen_losses = []\n",
    "    for i in range(len(fake_disc_output)):\n",
    "        result = fake_disc_output[i][-1]\n",
    "        l = torch.mean((1-result)**2)\n",
    "        # gen_losses.append(l)\n",
    "        loss += l\n",
    "    return loss, gen_losses"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:34.336938461Z",
     "start_time": "2023-08-20T20:23:34.333154078Z"
    }
   },
   "id": "abc97bd6688259b8"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def descriminator_loss(real_disc_output, fake_disc_output):\n",
    "    loss = 0\n",
    "    disc_losses = []\n",
    "    for i in range(len(real_disc_output)):\n",
    "        real_result = real_disc_output[i][-1]\n",
    "        fake_result = fake_disc_output[i][-1]\n",
    "        l = torch.mean((1-real_result)**2) + torch.mean((0-fake_result)**2)\n",
    "        # disc_losses.append(l)\n",
    "        loss += l\n",
    "    return loss, disc_losses"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:36.741142516Z",
     "start_time": "2023-08-20T20:23:36.739635958Z"
    }
   },
   "id": "9bff26f39f700ac1"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def feature_matching_loss(real_disc_output, fake_disc_output):\n",
    "    loss = 0\n",
    "    fm_losses = []\n",
    "    assert len(real_disc_output) == len(fake_disc_output)\n",
    "    # print(fake_disc_output.shape)\n",
    "    len_except_last = len(real_disc_output)\n",
    "    for i in range(len_except_last):\n",
    "        for j in range(len(real_disc_output[i])-1):\n",
    "            real_result = real_disc_output[i][j]\n",
    "            fake_result = fake_disc_output[i][j]\n",
    "            # l = torch.mean((real_result-fake_result)**2)\n",
    "            #mae loss\n",
    "            l = torch.mean(torch.abs(real_result-fake_result))\n",
    "            # fm_losses.append(l)\n",
    "            loss += l\n",
    "    return loss*2, fm_losses"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:38.224312410Z",
     "start_time": "2023-08-20T20:23:38.203605775Z"
    }
   },
   "id": "5234e94330db889b"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "LEARNING_RATE_GEN = 1e-6\n",
    "LEARNING_RATE_DISC = 1e-5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:38.978158539Z",
     "start_time": "2023-08-20T20:23:38.930465663Z"
    }
   },
   "id": "df2078157fc058e"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "generator = Generator().to(device)\n",
    "descriminator = Descriminator().to(device)\n",
    "generator_optimizer = Adam(generator.parameters(), lr=LEARNING_RATE_GEN, betas=(0.8, 0.99))\n",
    "descriminator_optimizer = Adam(descriminator.parameters(), lr=LEARNING_RATE_DISC,betas=(0.8, 0.999))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-20T20:23:39.990860639Z",
     "start_time": "2023-08-20T20:23:39.402021710Z"
    }
   },
   "id": "de86180c363705ef"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def train():\n",
    "    for epoch in range(600):\n",
    "        for i, data in enumerate(train_loader):\n",
    "            original_wav, mel = data\n",
    "            original_wav = original_wav.to(device)\n",
    "            mel = mel.to(device)\n",
    "            gen_out = generator(mel)\n",
    "            \n",
    "            descriminator_optimizer.zero_grad()\n",
    "            real_disc_output = descriminator(original_wav.detach())\n",
    "            fake_disc_output = descriminator(gen_out.detach())\n",
    "            disc_loss, disc_losses = descriminator_loss(real_disc_output, fake_disc_output)\n",
    "            disc_loss.backward()\n",
    "            descriminator_optimizer.step()\n",
    "            \n",
    "            generator_optimizer.zero_grad()\n",
    "            real_disc_output = descriminator(original_wav)\n",
    "            fake_disc_output = descriminator(gen_out)\n",
    "            gen_loss, gen_losses = generator_loss(fake_disc_output)\n",
    "            fm_loss, fm_losses = feature_matching_loss(real_disc_output, fake_disc_output)\n",
    "            total_gen_loss = gen_loss+10*fm_loss\n",
    "            total_gen_loss.backward()\n",
    "            generator_optimizer.step()\n",
    "            print(\"epoch: {}, iteration: {}, gen_loss: {}, disc_loss: {}, fm_loss: {}\".format(epoch, i, gen_loss, disc_loss, fm_loss))\n",
    "            # print(\"gen_losses: {}, disc_losses: {}, fm_losses: {}\".format(gen_losses, disc_losses, fm_losses))\n",
    "            # break\n",
    "        # break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T02:16:55.271973428Z",
     "start_time": "2023-08-21T02:16:55.271729016Z"
    }
   },
   "id": "a8d9eb0bd376068c"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[1], line 3\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain\u001B[39m():\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m600\u001B[39m):\n\u001B[0;32m----> 3\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[43mtrain_loader\u001B[49m):\n\u001B[1;32m      4\u001B[0m             original_wav, mel \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m      5\u001B[0m             original_wav \u001B[38;5;241m=\u001B[39m original_wav\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T02:16:57.522189649Z",
     "start_time": "2023-08-21T02:16:57.303639251Z"
    }
   },
   "id": "1f8747c592583370"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "302eac4aa7a731c0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
