{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "metadata": {
    "id": "bGU6NwlsXFSt",
    "ExecuteTime": {
     "end_time": "2023-10-09T09:18:15.669111748Z",
     "start_time": "2023-10-09T09:18:14.728753809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@title Import Dependencies\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuro/miniconda3/envs/test/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/kuro/miniconda3/envs/test/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "id": "_bNfVLRUYqZA",
    "ExecuteTime": {
     "end_time": "2023-10-09T09:18:22.112087925Z",
     "start_time": "2023-10-09T09:18:22.107676204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@title Define Hyperparameters\n",
    "\n",
    "input_size = 784 # img_size = (28,28) ---> 28*28=784 in total\n",
    "hidden_size = 500 # number of nodes at hidden layer\n",
    "num_classes = 10 # number of output classes discrete range [0,9]\n",
    "num_epochs = 20 # number of times which the entire dataset is passed throughout the model\n",
    "batch_size = 100 # the size of input data took for one iteration\n",
    "lr = 1e-3 # size of step"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "id": "lCsBCXMwbpH5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "84954da2-c527-4100-a709-1e5096825bb0",
    "ExecuteTime": {
     "end_time": "2023-10-09T09:18:53.818214857Z",
     "start_time": "2023-10-09T09:18:29.083769266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@title Downloading MNIST data\n",
    "\n",
    "train_data = dsets.MNIST(root = './data', train = True,\n",
    "                        transform = transforms.ToTensor(), download = True)\n",
    "\n",
    "test_data = dsets.MNIST(root = './data', train = False,\n",
    "                       transform = transforms.ToTensor())"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9912422 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "837bae0f3cb340c39254e27ea4fc7ed7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/28881 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1dcaf9ba9fdb488da0e153c29fd2ef01"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1648877 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38fdce5a59214bc3b220010f9bb6b11c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4542 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46b1d4b54b7443629b56ec3acc4281c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_data[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xBkfAdnAXyDj",
    "outputId": "d5aa5187-f579-4c36-cea1-78ccf90eaa64",
    "ExecuteTime": {
     "end_time": "2023-10-09T09:19:07.936713508Z",
     "start_time": "2023-10-09T09:19:07.923031029Z"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n           0.0000, 0.0000, 0.0000, 0.0000]]]),\n 5)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "id": "fL-YXTvghaz_",
    "ExecuteTime": {
     "end_time": "2023-10-09T09:19:32.108881300Z",
     "start_time": "2023-10-09T09:19:32.065097969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@title Define model class\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, num_classes):\n",
    "    super(Net,self).__init__()\n",
    "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "  def forward(self,x):\n",
    "    out = self.fc1(x)\n",
    "    out = self.relu(out)\n",
    "    out = self.fc2(out)\n",
    "    return out"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "id": "rfDPBdnYgfGp",
    "ExecuteTime": {
     "end_time": "2023-10-09T09:19:42.135778227Z",
     "start_time": "2023-10-09T09:19:42.131554951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@title Loading the data\n",
    "\n",
    "train_gen = torch.utils.data.DataLoader(dataset = train_data,\n",
    "                                             batch_size = batch_size,\n",
    "                                             shuffle = True)\n",
    "\n",
    "test_gen = torch.utils.data.DataLoader(dataset = test_data,\n",
    "                                      batch_size = batch_size,\n",
    "                                      shuffle = False)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "id": "-3EPEqbjjfAT",
    "ExecuteTime": {
     "end_time": "2023-10-09T09:20:27.826602146Z",
     "start_time": "2023-10-09T09:20:26.902753072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@title Build the model\n",
    "\n",
    "net = Net(input_size, hidden_size, num_classes)\n",
    "if torch.cuda.is_available():\n",
    "  net.cuda()"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "id": "ePLIwvAFj2zH",
    "ExecuteTime": {
     "end_time": "2023-10-09T09:20:52.697513654Z",
     "start_time": "2023-10-09T09:20:52.689257564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@title Define loss-function & optimizer\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam( net.parameters(), lr=lr)"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "id": "u75Xa5VckuTH",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "dbf84edc-60e5-4710-d348-68d6362eeb42",
    "ExecuteTime": {
     "end_time": "2023-10-09T09:21:32.037472236Z",
     "start_time": "2023-10-09T09:20:56.758536006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@title Training the model\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for i ,(images,labels) in enumerate(train_gen):\n",
    "    images = Variable(images.view(-1,28*28)).cuda()\n",
    "    labels = Variable(labels).cuda()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(images)\n",
    "    loss = loss_function(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (i+1) % 100 == 0:\n",
    "      print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, len(train_data)//batch_size, loss.data))"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [100/600], Loss: 0.2729\n",
      "Epoch [1/20], Step [200/600], Loss: 0.4147\n",
      "Epoch [1/20], Step [300/600], Loss: 0.2718\n",
      "Epoch [1/20], Step [400/600], Loss: 0.2175\n",
      "Epoch [1/20], Step [500/600], Loss: 0.1442\n",
      "Epoch [1/20], Step [600/600], Loss: 0.2070\n",
      "Epoch [2/20], Step [100/600], Loss: 0.0593\n",
      "Epoch [2/20], Step [200/600], Loss: 0.1434\n",
      "Epoch [2/20], Step [300/600], Loss: 0.1570\n",
      "Epoch [2/20], Step [400/600], Loss: 0.2006\n",
      "Epoch [2/20], Step [500/600], Loss: 0.1077\n",
      "Epoch [2/20], Step [600/600], Loss: 0.1095\n",
      "Epoch [3/20], Step [100/600], Loss: 0.0517\n",
      "Epoch [3/20], Step [200/600], Loss: 0.1174\n",
      "Epoch [3/20], Step [300/600], Loss: 0.1601\n",
      "Epoch [3/20], Step [400/600], Loss: 0.0253\n",
      "Epoch [3/20], Step [500/600], Loss: 0.0233\n",
      "Epoch [3/20], Step [600/600], Loss: 0.0436\n",
      "Epoch [4/20], Step [100/600], Loss: 0.0430\n",
      "Epoch [4/20], Step [200/600], Loss: 0.1635\n",
      "Epoch [4/20], Step [300/600], Loss: 0.0328\n",
      "Epoch [4/20], Step [400/600], Loss: 0.0355\n",
      "Epoch [4/20], Step [500/600], Loss: 0.0295\n",
      "Epoch [4/20], Step [600/600], Loss: 0.0235\n",
      "Epoch [5/20], Step [100/600], Loss: 0.0253\n",
      "Epoch [5/20], Step [200/600], Loss: 0.0109\n",
      "Epoch [5/20], Step [300/600], Loss: 0.0315\n",
      "Epoch [5/20], Step [400/600], Loss: 0.0864\n",
      "Epoch [5/20], Step [500/600], Loss: 0.1221\n",
      "Epoch [5/20], Step [600/600], Loss: 0.0466\n",
      "Epoch [6/20], Step [100/600], Loss: 0.0055\n",
      "Epoch [6/20], Step [200/600], Loss: 0.0989\n",
      "Epoch [6/20], Step [300/600], Loss: 0.0499\n",
      "Epoch [6/20], Step [400/600], Loss: 0.0458\n",
      "Epoch [6/20], Step [500/600], Loss: 0.0069\n",
      "Epoch [6/20], Step [600/600], Loss: 0.0300\n",
      "Epoch [7/20], Step [100/600], Loss: 0.0645\n",
      "Epoch [7/20], Step [200/600], Loss: 0.0179\n",
      "Epoch [7/20], Step [300/600], Loss: 0.0157\n",
      "Epoch [7/20], Step [400/600], Loss: 0.0212\n",
      "Epoch [7/20], Step [500/600], Loss: 0.0341\n",
      "Epoch [7/20], Step [600/600], Loss: 0.0203\n",
      "Epoch [8/20], Step [100/600], Loss: 0.0031\n",
      "Epoch [8/20], Step [200/600], Loss: 0.0051\n",
      "Epoch [8/20], Step [300/600], Loss: 0.0075\n",
      "Epoch [8/20], Step [400/600], Loss: 0.0129\n",
      "Epoch [8/20], Step [500/600], Loss: 0.0217\n",
      "Epoch [8/20], Step [600/600], Loss: 0.0111\n",
      "Epoch [9/20], Step [100/600], Loss: 0.0033\n",
      "Epoch [9/20], Step [200/600], Loss: 0.0375\n",
      "Epoch [9/20], Step [300/600], Loss: 0.0017\n",
      "Epoch [9/20], Step [400/600], Loss: 0.0196\n",
      "Epoch [9/20], Step [500/600], Loss: 0.0416\n",
      "Epoch [9/20], Step [600/600], Loss: 0.0107\n",
      "Epoch [10/20], Step [100/600], Loss: 0.0058\n",
      "Epoch [10/20], Step [200/600], Loss: 0.0026\n",
      "Epoch [10/20], Step [300/600], Loss: 0.0037\n",
      "Epoch [10/20], Step [400/600], Loss: 0.0190\n",
      "Epoch [10/20], Step [500/600], Loss: 0.0261\n",
      "Epoch [10/20], Step [600/600], Loss: 0.0355\n",
      "Epoch [11/20], Step [100/600], Loss: 0.0064\n",
      "Epoch [11/20], Step [200/600], Loss: 0.0153\n",
      "Epoch [11/20], Step [300/600], Loss: 0.0066\n",
      "Epoch [11/20], Step [400/600], Loss: 0.0048\n",
      "Epoch [11/20], Step [500/600], Loss: 0.0015\n",
      "Epoch [11/20], Step [600/600], Loss: 0.0311\n",
      "Epoch [12/20], Step [100/600], Loss: 0.0018\n",
      "Epoch [12/20], Step [200/600], Loss: 0.0031\n",
      "Epoch [12/20], Step [300/600], Loss: 0.0306\n",
      "Epoch [12/20], Step [400/600], Loss: 0.0038\n",
      "Epoch [12/20], Step [500/600], Loss: 0.0105\n",
      "Epoch [12/20], Step [600/600], Loss: 0.0066\n",
      "Epoch [13/20], Step [100/600], Loss: 0.0452\n",
      "Epoch [13/20], Step [200/600], Loss: 0.0087\n",
      "Epoch [13/20], Step [300/600], Loss: 0.0026\n",
      "Epoch [13/20], Step [400/600], Loss: 0.0082\n",
      "Epoch [13/20], Step [500/600], Loss: 0.0010\n",
      "Epoch [13/20], Step [600/600], Loss: 0.0054\n",
      "Epoch [14/20], Step [100/600], Loss: 0.0012\n",
      "Epoch [14/20], Step [200/600], Loss: 0.0024\n",
      "Epoch [14/20], Step [300/600], Loss: 0.0018\n",
      "Epoch [14/20], Step [400/600], Loss: 0.0096\n",
      "Epoch [14/20], Step [500/600], Loss: 0.0019\n",
      "Epoch [14/20], Step [600/600], Loss: 0.0492\n",
      "Epoch [15/20], Step [100/600], Loss: 0.0004\n",
      "Epoch [15/20], Step [200/600], Loss: 0.0005\n",
      "Epoch [15/20], Step [300/600], Loss: 0.0042\n",
      "Epoch [15/20], Step [400/600], Loss: 0.0017\n",
      "Epoch [15/20], Step [500/600], Loss: 0.0101\n",
      "Epoch [15/20], Step [600/600], Loss: 0.0017\n",
      "Epoch [16/20], Step [100/600], Loss: 0.0004\n",
      "Epoch [16/20], Step [200/600], Loss: 0.0029\n",
      "Epoch [16/20], Step [300/600], Loss: 0.0340\n",
      "Epoch [16/20], Step [400/600], Loss: 0.0273\n",
      "Epoch [16/20], Step [500/600], Loss: 0.0741\n",
      "Epoch [16/20], Step [600/600], Loss: 0.0241\n",
      "Epoch [17/20], Step [100/600], Loss: 0.0371\n",
      "Epoch [17/20], Step [200/600], Loss: 0.0040\n",
      "Epoch [17/20], Step [300/600], Loss: 0.0059\n",
      "Epoch [17/20], Step [400/600], Loss: 0.0001\n",
      "Epoch [17/20], Step [500/600], Loss: 0.0014\n",
      "Epoch [17/20], Step [600/600], Loss: 0.0035\n",
      "Epoch [18/20], Step [100/600], Loss: 0.0041\n",
      "Epoch [18/20], Step [200/600], Loss: 0.0029\n",
      "Epoch [18/20], Step [300/600], Loss: 0.0018\n",
      "Epoch [18/20], Step [400/600], Loss: 0.0011\n",
      "Epoch [18/20], Step [500/600], Loss: 0.0005\n",
      "Epoch [18/20], Step [600/600], Loss: 0.0001\n",
      "Epoch [19/20], Step [100/600], Loss: 0.0013\n",
      "Epoch [19/20], Step [200/600], Loss: 0.0011\n",
      "Epoch [19/20], Step [300/600], Loss: 0.0017\n",
      "Epoch [19/20], Step [400/600], Loss: 0.0004\n",
      "Epoch [19/20], Step [500/600], Loss: 0.0106\n",
      "Epoch [19/20], Step [600/600], Loss: 0.0016\n",
      "Epoch [20/20], Step [100/600], Loss: 0.0019\n",
      "Epoch [20/20], Step [200/600], Loss: 0.0007\n",
      "Epoch [20/20], Step [300/600], Loss: 0.0007\n",
      "Epoch [20/20], Step [400/600], Loss: 0.0012\n",
      "Epoch [20/20], Step [500/600], Loss: 0.0031\n",
      "Epoch [20/20], Step [600/600], Loss: 0.0004\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "id": "DTPvMW5jHB9X",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5cf2840f-4dc9-4c84-f113-e2f165d94770",
    "ExecuteTime": {
     "end_time": "2023-10-09T09:21:38.885425915Z",
     "start_time": "2023-10-09T09:21:38.619707348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@title Evaluating the accuracy of the model\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for images,labels in test_gen:\n",
    "  images = Variable(images.view(-1,28*28)).cuda()\n",
    "  labels = labels.cuda()\n",
    "\n",
    "  output = net(images)\n",
    "  _, predicted = torch.max(output,1)\n",
    "  correct += (predicted == labels).sum()\n",
    "  total += labels.size(0)\n",
    "\n",
    "print('Accuracy of the model: %.3f %%' %((100*correct)/(total+1)))"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 97.950 %\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in net.state_dict():\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PyNWJvXqEbiE",
    "outputId": "5a22b73e-5f8c-4dbe-e6ec-2558b0daa479",
    "ExecuteTime": {
     "end_time": "2023-10-09T09:21:58.569746876Z",
     "start_time": "2023-10-09T09:21:58.567345187Z"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "fc1.weight \t torch.Size([500, 784])\n",
      "fc1.bias \t torch.Size([500])\n",
      "fc2.weight \t torch.Size([10, 500])\n",
      "fc2.bias \t torch.Size([10])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(net.state_dict(), \"mnist.state_dict\")"
   ],
   "metadata": {
    "id": "WNl7kcTcEzXS",
    "ExecuteTime": {
     "end_time": "2023-10-09T09:22:00.501166825Z",
     "start_time": "2023-10-09T09:22:00.483138032Z"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
