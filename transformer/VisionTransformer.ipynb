{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:21:38.549646627Z",
     "start_time": "2023-10-31T11:21:38.507013452Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch \n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch import nn\n",
    "from dataclasses import dataclass\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "def img_to_patch(x, patch_size, flatten_channels=True):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        x - torch.Tensor representing the image of shape [B, C, H, W]\n",
    "        patch_size - Number of pixels per dimension of the patches (integer)\n",
    "        flatten_channels - If True, the patches will be returned in a flattened format\n",
    "                           as a feature vector instead of a image grid.\n",
    "    \"\"\"\n",
    "    B, C, H, W = x.shape\n",
    "    x = x.reshape(B, C, H//patch_size, patch_size, W//patch_size, patch_size)\n",
    "    x = x.permute(0, 2, 4, 1, 3, 5) # [B, H', W', C, p_H, p_W]\n",
    "    x = x.flatten(1,2)              # [B, H'*W', C, p_H, p_W]\n",
    "    if flatten_channels:\n",
    "        x = x.flatten(2,4)          # [B, H'*W', C*p_H*p_W]\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:21:38.800932455Z",
     "start_time": "2023-10-31T11:21:38.797760371Z"
    }
   },
   "id": "59db38cddc698b1e"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "[0, 1, 2, 3, 4, 5, 6, 7]"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "desired_classes = all_classes[0:8]\n",
    "desired_indices = [all_classes.index(cls) for cls in desired_classes]\n",
    "desired_indices"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T10:07:45.098250773Z",
     "start_time": "2023-10-31T10:07:45.094469387Z"
    }
   },
   "id": "44ee1ebfd4ac50f9"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "DATA_DIR=\"../data\"\n",
    "def get_cifar10_data_loader():\n",
    "    \"\"\"\n",
    "    Get the CIFAR10 data loader\n",
    "    \"\"\"\n",
    "    test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784])\n",
    "                                     ])\n",
    "    # For training, we add some augmentation. Networks are too powerful and would overfit.\n",
    "    train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.RandomResizedCrop((32,32),scale=(0.8,1.0),ratio=(0.9,1.1)),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784])\n",
    "                                         ])\n",
    "\n",
    "\n",
    "    # get the training and testing datasets\n",
    "    train_dataset = CIFAR10(root=DATA_DIR, train=True, transform=train_transform, download=True)\n",
    "    test_dataset = CIFAR10(root=DATA_DIR, train=False, transform=test_transform, download=True)\n",
    "    train_set, val_set = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
    "    # _, val_set = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
    "\n",
    "    return train_set, val_set, test_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:21:43.908432181Z",
     "start_time": "2023-10-31T11:21:43.905039722Z"
    }
   },
   "id": "699af8d3eeb56e96"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set, test_set = get_cifar10_data_loader()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:21:45.445001608Z",
     "start_time": "2023-10-31T11:21:44.429909767Z"
    }
   },
   "id": "7bd8ba9538787de"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "def filter_dataset(dataset):\n",
    "    filtered_indices = [i  for i,  (_, label) in enumerate(dataset) if label in desired_indices]\n",
    "    return torch.utils.data.Subset(dataset, filtered_indices)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T16:10:45.342350866Z",
     "start_time": "2023-10-30T16:10:45.337273252Z"
    }
   },
   "id": "d607719ad031923"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filter_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_set \u001B[38;5;241m=\u001B[39m \u001B[43mfilter_dataset\u001B[49m(train_set)\n\u001B[1;32m      2\u001B[0m val_set \u001B[38;5;241m=\u001B[39m filter_dataset(val_set)\n\u001B[1;32m      3\u001B[0m test_set \u001B[38;5;241m=\u001B[39m filter_dataset(test_set)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'filter_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_set = filter_dataset(train_set)\n",
    "val_set = filter_dataset(val_set)\n",
    "test_set = filter_dataset(test_set)\n",
    "print(f\"len of train set {len(train_set)} val set {len(val_set)} test set {len(test_set)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T06:11:51.909943213Z",
     "start_time": "2023-10-31T06:11:51.867149549Z"
    }
   },
   "id": "f2a78ac8c95292f8"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim:int =  256\n",
    "    hidden_dim:int = 512\n",
    "    n_heads:int = 8\n",
    "    n_layers:int = 6\n",
    "    patch_size:int = 4\n",
    "    n_channels = 3\n",
    "    n_patches = 64\n",
    "    n_classes = 10\n",
    "    dropout = 0.2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:21:49.378070964Z",
     "start_time": "2023-10-31T11:21:49.373389155Z"
    }
   },
   "id": "c973a30501c1fd03"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, args:ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        \n",
    "        self.wq = nn.Linear(self.dim, self.n_heads*self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(self.dim, self.n_heads*self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(self.dim, self.n_heads*self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(self.n_heads*self.head_dim, self.dim, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, seq_len, dim = x.shape\n",
    "        \n",
    "        assert dim == self.dim, \"dim is not matching\"\n",
    "        q = self.wq(x)\n",
    "        k = self.wk(x)\n",
    "        v = self.wv(x)\n",
    "        \n",
    "        q = q.contiguous().view(b, seq_len, self.n_heads, self.head_dim)\n",
    "        k = k.contiguous().view(b, seq_len, self.n_heads, self.head_dim)\n",
    "        v = v.contiguous().view(b, seq_len, self.n_heads, self.head_dim)\n",
    "        \n",
    "        q = q.transpose(1, 2)\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1,2)\n",
    "        \n",
    "        attn = torch.matmul(q, k. transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        attn_scores = F.softmax(attn, dim = -1)\n",
    "        \n",
    "        out = torch.matmul(attn_scores, v)\n",
    "        out = out.contiguous().view(b, seq_len, -1)\n",
    "        \n",
    "        return self.wo(out)        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:21:52.196435607Z",
     "start_time": "2023-10-31T11:21:52.194085942Z"
    }
   },
   "id": "19ec9440213a820a"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.layer_norm_1 = nn.LayerNorm(args.dim)\n",
    "        self.attn = MultiHeadAttention(args)\n",
    "        \n",
    "        self.layer_norm_2 = nn.LayerNorm(args.dim)\n",
    "        \n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(args.dim, args.hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(args.dropout),\n",
    "            nn.Linear(args.hidden_dim, args.dim),\n",
    "            nn.Dropout(args.dropout)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.layer_norm_1(x))\n",
    "        x = x + self.ffn(self.layer_norm_2(x))\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:21:53.330996267Z",
     "start_time": "2023-10-31T11:21:53.326656099Z"
    }
   },
   "id": "4c3f7596b4ec9009"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.patch_size = args.patch_size\n",
    "        \n",
    "        self.input_layer = nn.Linear(args.n_channels * (args.patch_size ** 2), args.dim)\n",
    "        attn_blocks = []\n",
    "        for _ in range(args.n_layers):\n",
    "            attn_blocks.append(AttentionBlock(args))\n",
    "        \n",
    "        self.transformer = nn.Sequential(*attn_blocks)\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.LayerNorm(args.dim),\n",
    "            nn.Linear(args.dim, args.n_classes)\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(args.dropout)\n",
    "        \n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, args.dim))\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, 1+args.n_patches, args.dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = img_to_patch(x, self.patch_size)\n",
    "        b, seq_len, _ = x.shape\n",
    "        x = self.input_layer(x)\n",
    "        \n",
    "        cls_token = self.cls_token.repeat(b, 1, 1)\n",
    "        x = torch.cat([cls_token, x], dim=1)\n",
    "        \n",
    "        x = x + self.pos_embedding[:,:seq_len+1]\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.transformer(x)\n",
    "        # print(\"========== x shape =====\", x.shape)\n",
    "        x = x.transpose(0, 1)\n",
    "        cls = x[0]\n",
    "        out = self.mlp(cls)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:21:54.206314410Z",
     "start_time": "2023-10-31T11:21:54.203948486Z"
    }
   },
   "id": "b51bde2d3d36e9c9"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "256"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = ModelArgs()\n",
    "args.dim"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:21:55.427375758Z",
     "start_time": "2023-10-31T11:21:55.423592528Z"
    }
   },
   "id": "228d8e565b8ac835"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "# Model, Loss and Optimizer\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else 0\n",
    "args = ModelArgs()\n",
    "model = VisionTransformer(args).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 150], gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:21:55.872717724Z",
     "start_time": "2023-10-31T11:21:55.845271672Z"
    }
   },
   "id": "816aefa5793746e0"
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "num_workers = 16\n",
    "# get the data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True,\n",
    "                                           num_workers=num_workers, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_set, batch_size=batch_size, shuffle=True,\n",
    "                                         num_workers=num_workers, drop_last=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False,\n",
    "                                          num_workers=num_workers, drop_last=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:22:20.383135535Z",
     "start_time": "2023-10-31T11:22:20.380412478Z"
    }
   },
   "id": "1388884734ae19ea"
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Training Loss: 1.6999\n",
      "Epoch [1/50], Validation Loss: 1.5045, Validation Accuracy: 45.68%\n",
      "Epoch [2/50], Training Loss: 1.4183\n",
      "Epoch [2/50], Validation Loss: 1.3412, Validation Accuracy: 51.46%\n",
      "Epoch [3/50], Training Loss: 1.3052\n",
      "Epoch [3/50], Validation Loss: 1.2789, Validation Accuracy: 54.12%\n",
      "Epoch [4/50], Training Loss: 1.2441\n",
      "Epoch [4/50], Validation Loss: 1.1980, Validation Accuracy: 56.50%\n",
      "Epoch [5/50], Training Loss: 1.1810\n",
      "Epoch [5/50], Validation Loss: 1.1757, Validation Accuracy: 57.78%\n",
      "Epoch [6/50], Training Loss: 1.1459\n",
      "Epoch [6/50], Validation Loss: 1.1456, Validation Accuracy: 59.66%\n",
      "Epoch [7/50], Training Loss: 1.1104\n",
      "Epoch [7/50], Validation Loss: 1.1171, Validation Accuracy: 60.24%\n",
      "Epoch [8/50], Training Loss: 1.0766\n",
      "Epoch [8/50], Validation Loss: 1.1127, Validation Accuracy: 60.40%\n",
      "Epoch [9/50], Training Loss: 1.0458\n",
      "Epoch [9/50], Validation Loss: 1.0516, Validation Accuracy: 63.28%\n",
      "Epoch [10/50], Training Loss: 1.0224\n",
      "Epoch [10/50], Validation Loss: 1.0277, Validation Accuracy: 63.30%\n",
      "Epoch [11/50], Training Loss: 0.9897\n",
      "Epoch [11/50], Validation Loss: 1.0764, Validation Accuracy: 62.40%\n",
      "Epoch [12/50], Training Loss: 0.9665\n",
      "Epoch [12/50], Validation Loss: 0.9885, Validation Accuracy: 65.40%\n",
      "Epoch [13/50], Training Loss: 0.9433\n",
      "Epoch [13/50], Validation Loss: 1.0050, Validation Accuracy: 64.72%\n",
      "Epoch [14/50], Training Loss: 0.9206\n",
      "Epoch [14/50], Validation Loss: 0.9721, Validation Accuracy: 65.60%\n",
      "Epoch [15/50], Training Loss: 0.8898\n",
      "Epoch [15/50], Validation Loss: 0.9529, Validation Accuracy: 66.24%\n",
      "Epoch [16/50], Training Loss: 0.8695\n",
      "Epoch [16/50], Validation Loss: 0.9544, Validation Accuracy: 67.14%\n",
      "Epoch [17/50], Training Loss: 0.8494\n",
      "Epoch [17/50], Validation Loss: 0.9397, Validation Accuracy: 67.06%\n",
      "Epoch [18/50], Training Loss: 0.8323\n",
      "Epoch [18/50], Validation Loss: 0.9327, Validation Accuracy: 67.90%\n",
      "Epoch [19/50], Training Loss: 0.8093\n",
      "Epoch [19/50], Validation Loss: 0.9189, Validation Accuracy: 67.96%\n",
      "Epoch [20/50], Training Loss: 0.7944\n",
      "Epoch [20/50], Validation Loss: 0.9323, Validation Accuracy: 67.48%\n",
      "Epoch [21/50], Training Loss: 0.7782\n",
      "Epoch [21/50], Validation Loss: 0.8998, Validation Accuracy: 68.76%\n",
      "Epoch [22/50], Training Loss: 0.7570\n",
      "Epoch [22/50], Validation Loss: 0.9224, Validation Accuracy: 67.96%\n",
      "Epoch [23/50], Training Loss: 0.7479\n",
      "Epoch [23/50], Validation Loss: 0.8879, Validation Accuracy: 69.04%\n",
      "Epoch [24/50], Training Loss: 0.7303\n",
      "Epoch [24/50], Validation Loss: 0.8992, Validation Accuracy: 68.88%\n",
      "Epoch [25/50], Training Loss: 0.7172\n",
      "Epoch [25/50], Validation Loss: 0.9031, Validation Accuracy: 68.68%\n",
      "Epoch [26/50], Training Loss: 0.7002\n",
      "Epoch [26/50], Validation Loss: 0.9011, Validation Accuracy: 68.94%\n",
      "Epoch [27/50], Training Loss: 0.6896\n",
      "Epoch [27/50], Validation Loss: 0.8620, Validation Accuracy: 70.24%\n",
      "Epoch [28/50], Training Loss: 0.6741\n",
      "Epoch [28/50], Validation Loss: 0.8784, Validation Accuracy: 69.68%\n",
      "Epoch [29/50], Training Loss: 0.6650\n",
      "Epoch [29/50], Validation Loss: 0.8822, Validation Accuracy: 69.12%\n",
      "Epoch [30/50], Training Loss: 0.6537\n",
      "Epoch [30/50], Validation Loss: 0.8605, Validation Accuracy: 70.66%\n",
      "Epoch [31/50], Training Loss: 0.6316\n",
      "Epoch [31/50], Validation Loss: 0.8665, Validation Accuracy: 69.68%\n",
      "Epoch [32/50], Training Loss: 0.6229\n",
      "Epoch [32/50], Validation Loss: 0.8829, Validation Accuracy: 70.56%\n",
      "Epoch [33/50], Training Loss: 0.6127\n",
      "Epoch [33/50], Validation Loss: 0.9040, Validation Accuracy: 69.98%\n",
      "Epoch [34/50], Training Loss: 0.6039\n",
      "Epoch [34/50], Validation Loss: 0.8693, Validation Accuracy: 71.82%\n",
      "Epoch [35/50], Training Loss: 0.5903\n",
      "Epoch [35/50], Validation Loss: 0.8985, Validation Accuracy: 70.36%\n",
      "Epoch [36/50], Training Loss: 0.5815\n",
      "Epoch [36/50], Validation Loss: 0.8742, Validation Accuracy: 70.58%\n",
      "Epoch [37/50], Training Loss: 0.5719\n",
      "Epoch [37/50], Validation Loss: 0.8965, Validation Accuracy: 70.52%\n",
      "Epoch [38/50], Training Loss: 0.5587\n",
      "Epoch [38/50], Validation Loss: 0.9256, Validation Accuracy: 69.62%\n",
      "Epoch [39/50], Training Loss: 0.5453\n",
      "Epoch [39/50], Validation Loss: 0.8924, Validation Accuracy: 70.58%\n",
      "Epoch [40/50], Training Loss: 0.5360\n",
      "Epoch [40/50], Validation Loss: 0.8924, Validation Accuracy: 71.16%\n",
      "Epoch [41/50], Training Loss: 0.5312\n",
      "Epoch [41/50], Validation Loss: 0.8469, Validation Accuracy: 71.50%\n",
      "Epoch [42/50], Training Loss: 0.5159\n",
      "Epoch [42/50], Validation Loss: 0.8710, Validation Accuracy: 71.36%\n",
      "Epoch [43/50], Training Loss: 0.5002\n",
      "Epoch [43/50], Validation Loss: 0.8875, Validation Accuracy: 71.82%\n",
      "Epoch [44/50], Training Loss: 0.4954\n",
      "Epoch [44/50], Validation Loss: 0.8929, Validation Accuracy: 72.16%\n",
      "Epoch [45/50], Training Loss: 0.4857\n",
      "Epoch [45/50], Validation Loss: 0.9040, Validation Accuracy: 71.42%\n",
      "Epoch [46/50], Training Loss: 0.4764\n",
      "Epoch [46/50], Validation Loss: 0.9254, Validation Accuracy: 71.64%\n",
      "Epoch [47/50], Training Loss: 0.4638\n",
      "Epoch [47/50], Validation Loss: 0.8767, Validation Accuracy: 72.06%\n",
      "Epoch [48/50], Training Loss: 0.4673\n",
      "Epoch [48/50], Validation Loss: 0.8786, Validation Accuracy: 72.22%\n",
      "Epoch [49/50], Training Loss: 0.4463\n",
      "Epoch [49/50], Validation Loss: 0.9310, Validation Accuracy: 71.18%\n",
      "Epoch [50/50], Training Loss: 0.4459\n",
      "Epoch [50/50], Validation Loss: 0.8743, Validation Accuracy: 72.82%\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50  # example value, adjust as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        # print(\"==== outputs shape ===\", outputs.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:  # Assuming val_loader is defined elsewhere\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            _, predicted = outputs.max(dim=-1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Update the learning rate\n",
    "    lr_scheduler.step()\n",
    "\n",
    "print(\"Training complete!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:30:44.422416188Z",
     "start_time": "2023-10-31T11:22:28.376779475Z"
    }
   },
   "id": "b675ed45e4aa2ed3"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "def test_accuracy():\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:  # Assuming val_loader is defined elsewhere\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "\n",
    "            _, predicted = outputs.max(dim=-1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:42:25.646514544Z",
     "start_time": "2023-10-31T11:42:25.642970767Z"
    }
   },
   "id": "c3edea32ec9d3337"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 71.70%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:42:27.654462061Z",
     "start_time": "2023-10-31T11:42:26.356466263Z"
    }
   },
   "id": "b654f33dd9d027c5"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "6.3857"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6.3857e+00"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:11:45.441705542Z",
     "start_time": "2023-10-31T11:11:45.401402846Z"
    }
   },
   "id": "95c4c7739b4127ab"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "13.028"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.3028e+01"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:12:03.389044915Z",
     "start_time": "2023-10-31T11:12:03.366555100Z"
    }
   },
   "id": "56118df1dd6d72d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4da2403816a364e4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
